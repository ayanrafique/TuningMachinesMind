<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://ayanrafique.github.io/TuningMachinesMind/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ayanrafique.github.io/TuningMachinesMind/" rel="alternate" type="text/html" /><updated>2020-03-20T16:58:57-05:00</updated><id>https://ayanrafique.github.io/TuningMachinesMind/feed.xml</id><title type="html">Tuning Machineâ€™s Mind</title><subtitle>Ruminations on various topics on machine learning, data science, music, physics, psychology, and all things in between.</subtitle><entry><title type="html">Transfer Learning for Pneumonia</title><link href="https://ayanrafique.github.io/TuningMachinesMind/markdown/2020/03/18/Transfer-Learning-for-Pneumonia.html" rel="alternate" type="text/html" title="Transfer Learning for Pneumonia" /><published>2020-03-18T00:00:00-05:00</published><updated>2020-03-18T00:00:00-05:00</updated><id>https://ayanrafique.github.io/TuningMachinesMind/markdown/2020/03/18/Transfer-Learning-for-Pneumonia</id><content type="html" xml:base="https://ayanrafique.github.io/TuningMachinesMind/markdown/2020/03/18/Transfer-Learning-for-Pneumonia.html">&lt;p&gt;Transfer learning was stated by Andrew Ng in his NIPS 2016 tutorial to be a key driver in the success of industrial applications. It can be shown that even in the handling of medical imaging data, that transfer learning can greatly reduce the costs of training over a dataset compared to the costs of training the same model from scratch. We will load up a simple usage given by Jeremy Howard of fast.ai, of the resnet-50 architecture, trained over the imagenet dataset. This model therefore has a, if you will, a sense of what the material world looks like. The pneumonia dataset we will be using is the kaggle dataset paultimothymooney/chest-xray-pneumonia.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rows&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/TuningMachinesMind/images/files.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This dataset is a collection of thousands of labeled files of  chest x-rays.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnn_learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resnet50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recorder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/TuningMachinesMind/images/lrfind.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here we use a method that was originally published in the 2015 paper &lt;a href=&quot;http://arxiv.org/abs/1506.01186&quot;&gt;Cyclical Learning Rates for Training Neural Networks&lt;/a&gt;. By simply increasing the learning rate incrementally from a small value and only stopping once the loss started decreasing, you can plot the learning rates. By doing this, one can find the optimal learning rate amongst the plot.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/TuningMachinesMind/images/error.PNG&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Implementing a method of tuning weights for the network, cycling over our data 8 epochs times, we get an error rate of 0.036721, which means our model is over 96% accurate! Not bad! Note that this was done without unfreezing the model and actually applying the learning rate for minimal loss. The default learning rate of 0.003 of the fit_one_cycle method gives appreciable results for this use case, while maintaining a steady lowering of the error rate through each cycling of the data.&lt;/p&gt;

&lt;p&gt;You can play around with this experimentation with the &lt;a href=&quot;https://github.com/ayanrafique/FastAiFun/blob/master/Pneumonia_detection.ipynb&quot;&gt;google colab file&lt;/a&gt;. You must download and upload your own kaggle.json file to use the code as is, which can be aquired after making a kaggle account.&lt;/p&gt;</content><author><name></name></author><summary type="html">Transfer learning was stated by Andrew Ng in his NIPS 2016 tutorial to be a key driver in the success of industrial applications. It can be shown that even in the handling of medical imaging data, that transfer learning can greatly reduce the costs of training over a dataset compared to the costs of training the same model from scratch. We will load up a simple usage given by Jeremy Howard of fast.ai, of the resnet-50 architecture, trained over the imagenet dataset. This model therefore has a, if you will, a sense of what the material world looks like. The pneumonia dataset we will be using is the kaggle dataset paultimothymooney/chest-xray-pneumonia.</summary></entry></feed>